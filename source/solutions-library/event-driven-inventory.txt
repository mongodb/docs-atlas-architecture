.. _arch-center-is-event-driven-inventory:

====================================================
Building an Event-Driven Inventory Management System
====================================================

.. facet::
   :name: genre
   :values: tutorial

.. meta:: 
   :keywords: Event-driven, Inventory, Atlas, Real-time analytics, Retail
   :description: Learn to build an event-driven inventory management system with real-time analytics and automation features for workforce efficiency with MongoDB Atlas.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Unlock real-time analytics, automation, and workforce efficiency in your
inventory operations for retail and manufacturing with MongoDB Atlas.

**Use cases:** `Catalog
<https://www.mongodb.com/solutions/use-cases/catalog>`__,
`Application-Driven Analytics
<https://www.mongodb.com/solutions/use-cases/analytics>`__

**Industries:** `Retail
<https://www.mongodb.com/industries/retail>`__,
`Manufacturing <https://www.mongodb.com/industries/manufacturing>`__

**Products:** `Change Streams <https://www.mongodb.com/docs/manual/changeStreams/>`__, 
`MongoDB Atlas Charts
<https://www.mongodb.com/products/platform/atlas-charts>`__, 
`MongoDB Atlas Search
<https://www.mongodb.com/products/platform/atlas-search>`__,
`MongoDB Atlas Triggers
<https://www.mongodb.com/docs/atlas/app-services/triggers/>`__

**Partners:** `Next.js <https://nextjs.org/>`__

Solution Overview
-----------------

**Executive summary**

In the competitive business landscape of retail and manufacturing,
having the right inventory of goods in the right place at the right time
is crucial. Insufficient inventory can lead to operational disruptions
and missed opportunities, while excess inventory can increase costs and
risks associated with storage. Companies of all sizes struggle with
inventory management. Solutions such as a single view of inventory,
real-time analytics, and event-driven architectures can help businesses
overcome these challenges and elevate their inventory management to the
next level. This demo will guide you through the process of building an
inventory management system with all the capabilities mentioned above,
tailored for diverse industries such as retail and manufacturing.

**Overview**

Effective inventory management is critical to ensure operational success
and customer service excellence. With the increasing complexity of
supply chains and rising customer expectations, businesses need robust
systems to track inventory levels, automate processes, and analyze
trends in real time. As industries continue to evolve, the importance of
integrated and event-driven inventory solutions becomes more pronounced
as they allow businesses to respond swiftly to market demands, minimize
costs, and maintain competitiveness.

Businesses must adopt strategies that allow for dynamic adjustments to
inventory levels, optimizing stock management, and reducing
inefficiencies. Automation and real-time data integration are key
components of these strategies. They provide the capabilities needed to
enhance operational agility, streamline supply chain processes, and
ensure timely delivery of products.

**Inventory management in the retail industry**

In today’s fast-paced retail landscape, ensuring your inventory is in
the right place at the right time is essential. However, the retail
industry faces significant challenges in achieving this goal. In 2022,
unsold stock in the U.S. surged by a staggering `$78 billion, reaching
approximately $740 billion — a shocking 12 percent increase
<https://www.mckinsey.com/industries/retail/our-insights/thinking-beyond-markdowns-to-tackle-retails-inventory-glut>`__.

Retailers today need a unified view of their inventory to meet customer
expectations for immediate availability and seamless purchasing
experiences. The disparity between online and in-store stock can lead to
missed sales opportunities and customer dissatisfaction.

Effective stock management enables retailers to leverage distributed
supply chains, moving inventory fluidly between channels to meet demand
where it arises. This reduces the risk of dead stock in physical stores
and stockouts in online channels, enhancing overall inventory
efficiency. Real-time analytics empower retailers to make data-driven
decisions, adapting quickly to changing market conditions and consumer
behavior. Furthermore, automated processes reduce manual errors and free
up staff to focus on value-added activities, such as enhancing service
quality. Event-driven architectures facilitate these improvements,
allowing for seamless inventory data integration and synchronization
across various platforms and devices.

.. figure:: /includes/images/industry-solutions/event-driven-overview.svg
   :figwidth: 1200px
   :alt: Real-time wind turbine diagnosis
   
   Figure 1. Inventory management overview.

**Closing the loop for a future-proof inventory management strategy**

MongoDB provides a leading component for modern inventory solutions. We
help businesses enhance service quality, workforce efficiency, and
optimize stock management by enabling a single view of inventory,
event-driven architectures, and real-time analytics. This solution lays
the groundwork for advanced scenarios such as integrating IoT and RFID
tags, delving into AI/ML forecasting for precise demand prediction, and
distributed logistics. The versatility of this solution allows its
application not only from warehouse to point of sale but also across the
entire supply chain, including manufacturing, transportation, retail,
and reverse logistics, making it a valuable asset for diverse business
domains.

.. video:: https://www.youtube.com/watch?v=sV2KfMk1CdM&t=371s
   
Reference Architectures
-----------------------

With MongoDB
~~~~~~~~~~~~

The inventory management solution leverages a `Next.js <https://nextjs.org/>`__ application
seamlessly integrated with `MongoDB Atlas <https://www.mongodb.com/atlas>`__, providing a flexible and
scalable backend. At the core of this architecture is a `MongoDB Atlas
Database <https://www.mongodb.com/products/platform/atlas-database>`__ that houses four key collections: products, transactions,
users, and locations. These collections are central to managing
inventory, processing transactions, and tracking user and location data.

MongoDB ensures data consistency and integrity through `ACID-compliant
operations
<https://www.mongodb.com/products/capabilities/transactions>`__. For
instance, when a stock level changes due to a
transaction, updates are made to both the products and transactions
collections in a way that guarantees reliability and consistency across
the system.

Data access between the Next.js application and MongoDB is facilitated
by the `MongoDB Node.js driver
<https://www.mongodb.com/docs/drivers/node/current/>`__, enabling
efficient retrieval and manipulation of information. To enhance the
application’s search capabilities, `Atlas Search
<https://www.mongodb.com/products/platform/atlas-search>`__ is utilized,
offering advanced full-text search features. This allows users to
perform complex queries, such as searching by product category or
applying filters through `facets
<https://www.mongodb.com/docs/atlas/atlas-search/tutorial/facet-tutorial/>`__,
improving the overall user experience with quick, intuitive searches.

The system's responsiveness is further enriched by `MongoDB Atlas
Triggers <https://www.mongodb.com/docs/atlas/atlas-ui/triggers/>`__ and
`Change Streams <https://www.mongodb.com/docs/manual/changeStreams/>`__.
Triggers automate backend logic by executing functions in response to
database changes. For example, when a product’s stock falls below a
certain threshold, a Trigger can automatically reorder inventory.
Meanwhile, Change Streams act as real-time listeners, detecting data
changes and pushing updates to the application instantly. This ensures
that critical alerts, such as low stock notifications, are promptly
delivered to inventory managers.

For real-time analytics, `Atlas Charts
<https://www.mongodb.com/products/platform/atlas-charts>`__ provides a
powerful tool to visualize data directly from MongoDB without the need
for ETL pipelines. This allows decision-makers to track key metrics,
like inventory levels or sales trends, in real time. With `workload
isolation
<https://www.mongodb.com/docs/manual/core/workload-isolation/>`__
enabled, analytics queries run on a dedicated node, ensuring that
operational performance remains unaffected. 

This cohesive architecture not only supports real-time data interactions
but also streamlines processes by automating key tasks. It allows the
Next.js application to provide a responsive and dynamic user experience,
underpinned by MongoDB’s robust data management features. Through this
integration, the solution effectively balances performance, automation,
and scalability, making it well-suited for modern inventory management
challenges.

Inventory management system
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. figure:: /includes/images/industry-solutions/event-driven-workflow.svg
   :figwidth: 1200px
   :alt: Inventory management workflow with Triggers and Change Streams.

   Figure 2. Event-driven workflow overview: Triggers allow automatic
   replenishment and Change Streams enable real-time low stock alerts.

Architecture with MongoDB
~~~~~~~~~~~~~~~~~~~~~~~~~

.. figure:: /includes/images/industry-solutions/event-driven-architecture.svg
   :figwidth: 1200px
   :alt: Inventory management system with MongoDB.

   Figure 3. Inventory management system architecture using MongoDB
   Atlas and Next.js.

Data Model Approach
-------------------

The primary collections — products, transactions, users and locations —
form the foundation of our inventory management system. These
collections represent your stock, incoming and outgoing movements that
affect stock levels, your app users, and the different locations that
the inventory system is serving.

What sets the document data model apart from traditional tabular models
is its remarkable flexibility, making it the perfect choice for
achieving a single view of inventory. With a tabular approach, achieving
a comprehensive overview of your inventory would typically involve
complex joins across multiple tables. However, with MongoDB's document
model, this complexity is eliminated. 

For instance, in the transactions collection we take advantage of the
`Extended Reference pattern
<https://www.mongodb.com/blog/post/building-with-patterns-the-extended-reference-pattern>`__
when referencing an item. We not only include the *product.id*, but also
the *product.name* to be displayed in the UI without the need of a join or
an extra query to the products collection.

If we now consider the products collection, we see how it encompasses
what would have otherwise demanded over 10 tables in a relational
system. For example, the product variants are contained as an embedded
array in the same document, and other attributes such as product stock
or locations would traditionally require additional tables. This
transformational power stems from the document model's inherent
flexibility. It not only empowers a more intuitive design but also
ensures that related data is stored together, optimizing access.

Equivalent relational model for products
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. figure:: /includes/images/industry-solutions/event-driven-data-model.svg
   :figwidth: 1200px
   :alt: Equivalent relational model for product.

   Figure 4. Product collection equivalent in a tabular setup.

Document model
~~~~~~~~~~~~~~

.. figure:: /includes/images/industry-solutions/event-driven-document-model.svg
   :figwidth: 1200px
   :alt: Database model with MongoDB.

   Figure 5. Take note of how complex objects and arrays are embedded
   directly within the document.

.. code-block:: javascript
   :copyable: true

   {
   "type": "inbound",
   "location": {
      "origin": {
         "type": "warehouse"
      },
      "destination": {
         "type": "factory",
         "id": {
         "$oid": "65c63cb61526ffd3415fadbd"
         },
         "name": "Bogatell Factory"
      }
   },
   "placement_timestamp": {
      "$date": "2024-04-08T15:13:58.822Z"
   },
   "items": [
      {
         "sku": "CT001-PT-MDB0001",
         "name": "Programmable Thermostats",
         "unit": "pieces",
         "delivery_time": {
         "amount": 3,
         "unit": "seconds"
         },
         "status": [
         {
            "name": "placed",
            "update_timestamp": {
               "$date": "2024-04-08T15:13:58.822Z"
            }
         },
         {
            "name": "arrived",
            "update_timestamp": {
               "$date": "2024-04-08T15:14:03.741Z"
            }
         }
         ],
         "amount": 15,
         "product": {
         "id": {
            "$oid": "65cce1a4ccdfb7402dbb4db4"
         },
         "name": "Controls and Thermostats",
         "image": {
            "url": "/images/products/thermostats.png"
         }
         }
      }
   ],
   "automatic": true,
   "transaction_number": 133
   }

Building the Solution
---------------------

In the `GitHub repository
<https://github.com/dsdlt/mongodb-scalable-document-embeddings>`__ you will
find detailed instructions on how to build the solution to update your 
embeddings asynchronously and at scale, leveraging MongoDB Atlas.

.. procedure::
   :style: normal

   .. step:: Create a MongoDB cluster

      The first step is to create a MongoDB cluster. If you don't have an 
      Atlas account, create one following the steps in this link: https://www.mongodb.com/docs/guides/atlas/account/

      We will create a cluster in Atlas using AWS as our cloud provider and
      us-east-1 as our region. Additionally, create an Atlas Stream Processing
      Instance (SPI) following the instructions in the documentation:
      https://www.mongodb.com/docs/atlas/atlas-sp/manage-processing-instance/
      
   .. step:: Create a Kafka cluster in Confluent

      To create a Kafka cluster in Confluent Cloud follow the instructions in 
      their documentation: https://docs.confluent.io/cloud/current/clusters/create-cluster.html#create-ak-clusters

      Once you have created the cluster, go to cluster settings and copy the
      bootstrap URL.

      .. figure:: /includes/images/industry-solutions/createkafkacluster1.png
         :figwidth: 750px
         :alt: Kafka cluster settings
      
      Then, create an API key to connect to your cluster.

      .. figure:: /includes/images/industry-solutions/createkafkacluster2.png
         :figwidth: 750px
         :alt: API key settings

      The next step is to configure the topics for use in this solution:
      SpanishInputTopic, EnglishInputTopic, and OutputTopic.
      
      .. figure:: /includes/images/industry-solutions/createkafkacluster3.png
         :figwidth: 1200px
         :alt: Topic settings

   .. step:: Configure the Stream Processing connection registry

      To configure a new connection, click the configure button in the Stream
      Processing Instance, then click Connection Registry and add a new 
      connection.

      You will use this to connect the Atlas Stream Processing Instance with 
      the Kafka Cluster.

      Once you have created your Kafka cluster, Confluent will provide you with
      the bootstrap server URL, username, and password for the Connection
      Registry.
      
      .. figure:: /includes/images/industry-solutions/configurespconnection1.png
         :figwidth: 1200px
         :alt: Stream Processing connection registry settings

      Next, create a connection from the Atlas Stream Processing Instance to
      the MongoDB Atlas cluster.
      
      .. figure:: /includes/images/industry-solutions/configurespconnection2.png
         :figwidth: 1200px
         :alt: Stream Processing to Atlas settings

   .. step:: Connect to the Stream Processing Instance

      To configure the pipelines and connections in the Stream Processing 
      Instance, you can connect to the cluster using the Mongo Shell (mongosh).

      When clicking on the Connect button in the Stream Processing Instance, 
      the Atlas UI provides instructions on connecting to the instance.

      .. figure:: /includes/images/industry-solutions/connectstreamprocessing1.png
         :figwidth: 1200px
         :alt: Connect to Stream Processing

   .. step:: Configuring Atlas Stream Processing

      You can follow the steps to configure Atlas Stream Processing in the
      README file in the GitHub repo. There you will learn how to create the
      pipelines to subscribe to changes in MongoDB, emit to each
      language-specific topic, and merge the events containing the processed
      data with the embeddings received from the Kafka cluster into MongoDB 
      using a MongoDB aggregation stage.

   .. step:: Create the Atlas Vector Search indexes

      Next, you will create language-specific vector indexes in Atlas Search.

      Visit the `Atlas Vector Search Quick Start guide <https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/vector-search-quick-start/?tck=ai_as_web>`__ 
      and start building smarter searches.

      The definition for the Atlas Vector Search Index for Spanish is as 
      follows:

      .. code-block:: javascript
         :copyable: true

         {
            "fields": [
               {
                  "type": "vector",
                  "path": "lyrics_embeddings_es",
                  "numDimensions": 768,
                  "similarity": "cosine"
               }
            ]
         }

      The definition for the Atlas Vector Search Index for English is as
      follows:
      
      .. code-block:: javascript
         :copyable: true

         {
            "fields": [
               {
                  "type": "vector",
                  "path": "lyrics_embeddings_en",
                  "numDimensions": 384,
                  "similarity": "cosine"
               }
            ]
         }

   .. step:: Run the metadata service

      The metadata service is a Python script that will subscribe to the input
      topics, create the tags and embeddings for the corresponding language
      according to the information received in the event, and write the event 
      to the output topic.

   .. step:: Run a semantic search

      We created a script in Python to help you interactively run semantic
      queries. You can find the script in the repository under the client 
      folder.

Key Learnings
-------------

Throughout this solution, we’ve covered multiple MongoDB topics. Here’s
a quick recap of the key learnings: 

- **Real-time alerts** Implement real-time low-stock alerts in your
  frontend using Change Streams. 

- **Workflow automation:** Leverage database triggers to
  automate stock replenishment workflows.

- **Real-time analytics:** Stay on top of your data, analyze trends, and
  make informed decisions in a timely manner with Atlas Charts.

- **Single view of inventory:** Take advantage of the
  flexibility of the document model to create a comprehensive single view
  of inventory. 

Remember that this is just the beginning. Feel free to explore, tweak, and enhance your inventory management system to fit your own needs.

Technologies and Products Used
------------------------------

MongoDB Developer Data Platform
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- `MongoDB Atlas Search <https://www.mongodb.com/products/platform/atlas-search>`__
- `MongoDB Aggregation Pipeline <https://www.mongodb.com/resources/products/capabilities/aggregation-pipeline>`__
- `Change Streams <https://www.mongodb.com/products/platform/atlas-stream-processing>`__
- `MongoDB Atlas Charts <https://www.mongodb.com/docs/charts/>`__
- `MongoDB Node.js driver <https://www.mongodb.com/docs/drivers/node/current/>`__
- `MongoDB Atlas Triggers <https://www.mongodb.com/docs/atlas/atlas-ui/triggers/>`__

Partner Technologies
~~~~~~~~~~~~~~~~~~~~

- Next.js `<https://nextjs.org/>`__
- React `<https://react.dev/>`__

Author
------

- Dr. Humza Akhtar, MongoDB
- Ramiro Pinto Prieto, MongoDB 
- Tamar Alphaidze, MongoDB

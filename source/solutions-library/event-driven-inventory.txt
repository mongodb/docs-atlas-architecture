.. _arch-center-is-event-driven-inventory:

====================================================
Building an Event-Driven Inventory Management System
====================================================

.. facet::
   :name: genre
   :values: tutorial

.. meta:: 
   :keywords: Event-driven, Inventory, Atlas, Real-time analytics, Retail
   :description: Learn to build an event-driven inventory management system with real-time analytics and automation features for workforce efficiency with MongoDB Atlas.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Unlock real-time analytics, automation, and workforce efficiency in your
inventory operations for retail and manufacturing with MongoDB Atlas.

**Use cases:** `Catalog
<https://www.mongodb.com/solutions/use-cases/catalog>`__,
`Application-Driven Analytics
<https://www.mongodb.com/solutions/use-cases/analytics>`__

**Industries:** `Retail
<https://www.mongodb.com/industries/retail>`__,
`Manufacturing <https://www.mongodb.com/industries/manufacturing>`__

**Products:** `Change Streams <https://www.mongodb.com/docs/manual/changeStreams/>`__, 
`MongoDB Atlas Charts
<https://www.mongodb.com/products/platform/atlas-charts>`__, 
`MongoDB Atlas Search
<https://www.mongodb.com/products/platform/atlas-search>`__,
`MongoDB Atlas Triggers
<https://www.mongodb.com/docs/atlas/app-services/triggers/>`__

**Partners:** `Next.js <https://nextjs.org/>`__

Solution Overview
-----------------

**Executive summary**

In the competitive business landscape of retail and manufacturing,
having the right inventory of goods in the right place at the right time
is crucial. Insufficient inventory can lead to operational disruptions
and missed opportunities, while excess inventory can increase costs and
risks associated with storage. Companies of all sizes struggle with
inventory management. Solutions such as a single view of inventory,
real-time analytics, and event-driven architectures can help businesses
overcome these challenges and elevate their inventory management to the
next level. This demo will guide you through the process of building an
inventory management system with all the capabilities mentioned above,
tailored for diverse industries such as retail and manufacturing.

**Overview**

Effective inventory management is critical to ensure operational success
and customer service excellence. With the increasing complexity of
supply chains and rising customer expectations, businesses need robust
systems to track inventory levels, automate processes, and analyze
trends in real time. As industries continue to evolve, the importance of
integrated and event-driven inventory solutions becomes more pronounced
as they allow businesses to respond swiftly to market demands, minimize
costs, and maintain competitiveness.

Businesses must adopt strategies that allow for dynamic adjustments to
inventory levels, optimizing stock management, and reducing
inefficiencies. Automation and real-time data integration are key
components of these strategies. They provide the capabilities needed to
enhance operational agility, streamline supply chain processes, and
ensure timely delivery of products.

**Inventory management in the retail industry**

In today’s fast-paced retail landscape, ensuring your inventory is in
the right place at the right time is essential. However, the retail
industry faces significant challenges in achieving this goal. In 2022,
unsold stock in the U.S. surged by a staggering `$78 billion, reaching
approximately $740 billion — a shocking 12 percent increase
<https://www.mckinsey.com/industries/retail/our-insights/thinking-beyond-markdowns-to-tackle-retails-inventory-glut>`__.

Retailers today need a unified view of their inventory to meet customer
expectations for immediate availability and seamless purchasing
experiences. The disparity between online and in-store stock can lead to
missed sales opportunities and customer dissatisfaction.

Effective stock management enables retailers to leverage distributed
supply chains, moving inventory fluidly between channels to meet demand
where it arises. This reduces the risk of dead stock in physical stores
and stockouts in online channels, enhancing overall inventory
efficiency. Real-time analytics empower retailers to make data-driven
decisions, adapting quickly to changing market conditions and consumer
behavior. Furthermore, automated processes reduce manual errors and free
up staff to focus on value-added activities, such as enhancing service
quality. Event-driven architectures facilitate these improvements,
allowing for seamless inventory data integration and synchronization
across various platforms and devices.

.. figure:: /includes/images/industry-solutions/event-driven-overview.svg
   :figwidth: 1200px
   :alt: Real-time wind turbine diagnosis
   
   Figure 1. Inventory management overview

**Closing the loop for a future-proof inventory management strategy**

MongoDB provides a leading component for modern inventory solutions. We
help businesses enhance service quality, workforce efficiency, and
optimize stock management by enabling a single view of inventory,
event-driven architectures, and real-time analytics. This solution lays
the groundwork for advanced scenarios such as integrating IoT and RFID
tags, delving into AI/ML forecasting for precise demand prediction, and
distributed logistics. The versatility of this solution allows its
application not only from warehouse to point of sale but also across the
entire supply chain, including manufacturing, transportation, retail,
and reverse logistics, making it a valuable asset for diverse business
domains.

.. video:: https://www.youtube.com/watch?v=sV2KfMk1CdM&t=371s
   
Reference Architectures
-----------------------

With MongoDB
~~~~~~~~~~~~

The inventory management solution leverages a `Next.js <https://nextjs.org/>`__ application
seamlessly integrated with MongoDB Atlas, providing a flexible and
scalable backend. At the core of this architecture is a MongoDB Atlas
Database that houses four key collections: products, transactions,
users, and locations. These collections are central to managing
inventory, processing transactions, and tracking user and location data.

MongoDB ensures data consistency and integrity through ACID-compliant
operations. For instance, when a stock level changes due to a
transaction, updates are made to both the products and transactions
collections in a way that guarantees reliability and consistency across
the system.

Data access between the Next.js application and MongoDB is facilitated
by the MongoDB Node.js driver, enabling efficient retrieval and
manipulation of information. To enhance the application’s search
capabilities, Atlas Search is utilized, offering advanced full-text
search features. This allows users to perform complex queries, such as
searching by product category or applying filters through facets,
improving the overall user experience with quick, intuitive searches.

The system's responsiveness is further enriched by MongoDB Triggers and
Change Streams. Triggers automate backend logic by executing functions
in response to database changes. For example, when a product’s stock
falls below a certain threshold, a Trigger can automatically reorder
inventory. Meanwhile, Change Streams act as real-time listeners,
detecting data changes and pushing updates to the application instantly.
This ensures that critical alerts, such as low stock notifications, are
promptly delivered to inventory managers.

For real-time analytics, Atlas Charts provides a powerful tool to
visualize data directly from MongoDB without the need for ETL pipelines.
This allows decision-makers to track key metrics, like inventory levels
or sales trends, in real time. With workload isolation enabled,
analytics queries run on a dedicated node, ensuring that operational
performance remains unaffected. 


Inventory management system
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. figure:: /includes/images/industry-solutions/event-driven-workflow.svg
   :figwidth: 1200px
   :alt: Inventory management workflow with Triggers and Change Streams.

   Figure 2. Event-driven workflow overview: Triggers allow automatic
   replenishment and Change Streams enable real-time low stock alerts.

Architecture with MongoDB
~~~~~~~~~~~~~~~~~~~~~~~~~

.. figure:: /includes/images/industry-solutions/event-driven-architecture.svg
   :figwidth: 1200px
   :alt: Inventory management system with MongoDB.

   Figure 3. Inventory management system architecture using MongoDB
   Atlas and Next.js.

Data Model Approach
-------------------

.. code-block:: javascript
   :copyable: true

   {
      "title": "Hurricane",
      "genre": "rock",
      "artist": "Bob Dylan",
      "year": 1976,
      "views": 307418,
      "lyrics": "...",
      "language": "en",
      "duration": 61,
      "lyrics_embeddings_en": [...],
      "tags": ["man", "story", "night"]
   }

The data we currently have about the song consists of the following fields:

- **Title:** Name of the song
- **Genre:** a single-worded string containing a music style from a list of 6 
  genres
- **Artist:** Name of the artist
- **Year:** The year in which the song was written
- **Views:** Number of times the song has been listened to
- **Lyrics:** A string field containing the lyrics with each line separated by 
  a new line delimiter
- **Language:** The language of the lyrics in ISO-369. We are only storing 
  songs in English and Spanish.
- **Duration:** Duration of the song in seconds
- **Lyrics embedding vector:** language-specific embeddings vector
- **Tags:** A list of tags associated with the lyrics

The benefit of using the document data model is that it allows you to store all
the related information of a song in a single document for easy and fast 
retrieval.

Building the Solution
---------------------

In the `GitHub repository
<https://github.com/dsdlt/mongodb-scalable-document-embeddings>`__ you will
find detailed instructions on how to build the solution to update your 
embeddings asynchronously and at scale, leveraging MongoDB Atlas.

.. procedure::
   :style: normal

   .. step:: Create a MongoDB cluster

      The first step is to create a MongoDB cluster. If you don't have an 
      Atlas account, create one following the steps in this link: https://www.mongodb.com/docs/guides/atlas/account/

      We will create a cluster in Atlas using AWS as our cloud provider and
      us-east-1 as our region. Additionally, create an Atlas Stream Processing
      Instance (SPI) following the instructions in the documentation:
      https://www.mongodb.com/docs/atlas/atlas-sp/manage-processing-instance/
      
   .. step:: Create a Kafka cluster in Confluent

      To create a Kafka cluster in Confluent Cloud follow the instructions in 
      their documentation: https://docs.confluent.io/cloud/current/clusters/create-cluster.html#create-ak-clusters

      Once you have created the cluster, go to cluster settings and copy the
      bootstrap URL.

      .. figure:: /includes/images/industry-solutions/createkafkacluster1.png
         :figwidth: 750px
         :alt: Kafka cluster settings
      
      Then, create an API key to connect to your cluster.

      .. figure:: /includes/images/industry-solutions/createkafkacluster2.png
         :figwidth: 750px
         :alt: API key settings

      The next step is to configure the topics for use in this solution:
      SpanishInputTopic, EnglishInputTopic, and OutputTopic.
      
      .. figure:: /includes/images/industry-solutions/createkafkacluster3.png
         :figwidth: 1200px
         :alt: Topic settings

   .. step:: Configure the Stream Processing connection registry

      To configure a new connection, click the configure button in the Stream
      Processing Instance, then click Connection Registry and add a new 
      connection.

      You will use this to connect the Atlas Stream Processing Instance with 
      the Kafka Cluster.

      Once you have created your Kafka cluster, Confluent will provide you with
      the bootstrap server URL, username, and password for the Connection
      Registry.
      
      .. figure:: /includes/images/industry-solutions/configurespconnection1.png
         :figwidth: 1200px
         :alt: Stream Processing connection registry settings

      Next, create a connection from the Atlas Stream Processing Instance to
      the MongoDB Atlas cluster.
      
      .. figure:: /includes/images/industry-solutions/configurespconnection2.png
         :figwidth: 1200px
         :alt: Stream Processing to Atlas settings

   .. step:: Connect to the Stream Processing Instance

      To configure the pipelines and connections in the Stream Processing 
      Instance, you can connect to the cluster using the Mongo Shell (mongosh).

      When clicking on the Connect button in the Stream Processing Instance, 
      the Atlas UI provides instructions on connecting to the instance.

      .. figure:: /includes/images/industry-solutions/connectstreamprocessing1.png
         :figwidth: 1200px
         :alt: Connect to Stream Processing

   .. step:: Configuring Atlas Stream Processing

      You can follow the steps to configure Atlas Stream Processing in the
      README file in the GitHub repo. There you will learn how to create the
      pipelines to subscribe to changes in MongoDB, emit to each
      language-specific topic, and merge the events containing the processed
      data with the embeddings received from the Kafka cluster into MongoDB 
      using a MongoDB aggregation stage.

   .. step:: Create the Atlas Vector Search indexes

      Next, you will create language-specific vector indexes in Atlas Search.

      Visit the `Atlas Vector Search Quick Start guide <https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/vector-search-quick-start/?tck=ai_as_web>`__ 
      and start building smarter searches.

      The definition for the Atlas Vector Search Index for Spanish is as 
      follows:

      .. code-block:: javascript
         :copyable: true

         {
            "fields": [
               {
                  "type": "vector",
                  "path": "lyrics_embeddings_es",
                  "numDimensions": 768,
                  "similarity": "cosine"
               }
            ]
         }

      The definition for the Atlas Vector Search Index for English is as
      follows:
      
      .. code-block:: javascript
         :copyable: true

         {
            "fields": [
               {
                  "type": "vector",
                  "path": "lyrics_embeddings_en",
                  "numDimensions": 384,
                  "similarity": "cosine"
               }
            ]
         }

   .. step:: Run the metadata service

      The metadata service is a Python script that will subscribe to the input
      topics, create the tags and embeddings for the corresponding language
      according to the information received in the event, and write the event 
      to the output topic.

   .. step:: Run a semantic search

      We created a script in Python to help you interactively run semantic
      queries. You can find the script in the repository under the client 
      folder.

Key Learnings
-------------

- **Maintain embedding relevancy:** Regularly update data embeddings to ensure
  your semantic searches remain accurate, especially if your documents change 
  frequently.
- **Optimize language-model pairing:** To maximize semantic search accuracy,
  ensure your large language model (LLM) closely aligns with the language of
  your data to significantly enhance the relevance and precision of your search results.
- **Embrace Flexible Embeddings:** MongoDB's flexible data model eliminates the
  need for rigid schema definitions. This flexibility allows you to store
  embeddings directly alongside your data, regardless of their length or the 
  model used to generate them.
- **Choose the right similarity function:** The effectiveness of your semantic
  searches depends on the chosen similarity function. Tailor your selection to 
  your specific use case.
- **Asynchronous Embedding Generation:** Generating embeddings can be
  computationally expensive. Consider running this task asynchronously to avoid
  impacting your application's performance. Leverage the cloud's elasticity by
  horizontally scaling the functions responsible for embedding generation to 
  handle bursts in workload.

Technologies and Products Used
------------------------------

MongoDB Developer Data Platform
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- `Atlas Database <http://mongodb.com/atlas>`__
- `Atlas Vector Search <https://www.mongodb.com/products/platform/atlas-vector-search>`__
- `Atlas Stream Processing <https://www.mongodb.com/products/platform/atlas-stream-processing>`__

Partner Technologies
~~~~~~~~~~~~~~~~~~~~

- Confluent Cloud
- AWS EC2

Author
------

David Sanchez, MongoDB
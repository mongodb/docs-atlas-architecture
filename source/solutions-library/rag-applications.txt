.. _arch-center-is-rag-applications:

===============================================
Building Continuously Updating RAG Applications
===============================================

.. facet::
   :name: genre
   :values: tutorial

.. meta:: 
   :keywords: RAG, Atlas
   :description: Use native stream processing and vector search in MongoDB Atlas to continuously update, store, and search embeddings through a unified interface.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Use MongoDB Atlas native stream processing and vector search to continuously
update, store, and search embeddings through a unified interface.

**Use cases:** `Gen AI
<https://www.mongodb.com/use-cases/artificial-intelligence>`__

**Industries:** `Finance
<https://www.mongodb.com/industries/financial-services>`__,
`Healthcare <https://www.mongodb.com/industries/healthcare>`__, `Retail
<https://www.mongodb.com/industries/retail>`__

**Products:** `Atlas <http://mongodb.com/atlas>`__, `Atlas Vector Search
<https://www.mongodb.com/products/platform/atlas-vector-search>`__, `Atlas
Stream Processing
<https://www.mongodb.com/products/platform/atlas-stream-processing>`__

**Partners:** `Confluent <http://confluent.io/>`__, `AWS <https://aws.amazon.com/>`__

Solution Overview
-----------------

Providing AI models with up-to-date data is essential to delivering a
differentiated experience. Retrieval-augmented generation (`RAG
<https://www.mongodb.com/basics/retrieval-augmented-generation>`__) systems
enable organizations to ground large language models (`LLMs
<https://www.mongodb.com/basics/large-language-models>`__) and other
foundational models in the truth of their proprietary data. However, maintaining
the freshness of the underlying data introduces a layer of complexity.

To ensure models provide accurate answers, it is essential to continuously
update the vector embeddings that form the core of RAG systems to represent the
latest information available. 

Furthermore, the choice of embedding model impacts the quality of AI outputs due
to how different models are optimized for varying purposes and data types. For
example, an embedding model trained on a particular language will create more
contextually appropriate embeddings for that language than a general-purpose
model trained across many languages.

By leveraging MongoDB Atlas' native `Stream Processing
<https://www.mongodb.com/products/platform/atlas-stream-processing>`__ and
`Vector Search
<https://www.mongodb.com/products/platform/atlas-vector-search>`__ capabilities,
this solution addresses this issue of continuously updating and routing vector
embeddings in a RAG system. With this solution, developers can continuously
update, store, and search embeddings within a single interface.

This solution is relevant to many industries and use cases, including:

- **Financial services:** Financial documents, legal policies, and contracts
  often use multiple languages and differ based on country regulations.
  Empowering loan officers with an AI-powered interface using relevant and fresh
  data for expediting loan creation can optimize banking workflows.

- **Healthcare and Insurance:** From constantly updating patient records to 
  AI-powered underwriting of insurance policies, itâ€™s important that any RAG 
  system that optimizes these processes has access to the latest information.

- **Retail:** Personalizing retail experiences for customers is critical.
  However, consider the many languages that shoppers might use and product
  descriptions that have to match. Routing up-to-date, contextual data to the
  most accurate embedding model can improve these experiences.

Reference Architectures
-----------------------

- **MongoDB Atlas Cluster:** Enables the flexible storage of various data types
  including text, associated metadata, and corresponding vector embeddings in
  documents. Atlas's vector index capability directly supports efficient
  semantic search queries within the database, which can be leveraged through
  the `MongoDB Aggregation Framework
  <https://www.mongodb.com/basics/aggregation>`__.

- **Atlas Stream Processing:** Subscribes to the event streams generated by
  MongoDB, filters relevant information, transforms events, and emits them to
  the corresponding Kafka topic. It also subscribes to the Kafka cluster to
  process updates and propagate changes back to the database.

- **Confluent Kafka Cluster:** Receives document updates and new documents from
  producers and makes them available for further processing by Atlas Stream
  Processing.

- **Metadata Service:**

  - **Embedding Generator:** Python script that subscribes to the Kafka input
    topics. For each message received, it generates an embedding using a
    specialized machine learning model.

  - **Tags Extractor:** Python script that analyzes incoming data to identify
    relevant structured metadata to enrich the document for indexing, search, or
    analysis.

.. figure:: /includes/images/industry-solutions/RefArchitecture_StreamProcessing_WithMongoDB.svg
   :figwidth: 1200px
   :alt: Scalable vector updates reference architecture with MongoDB

   Figure 1. Scalable vector updates reference architecture with MongoDB

Data Model Approach
-------------------

.. code-block:: javascript
   :copyable: true

   {
      "title": "Hurricane",
      "genre": "rock",
      "artist": "Bob Dylan",
      "year": 1976,
      "views": 307418,
      "lyrics": "...",
      "language": "en",
      "duration": 61,
      "lyrics_embeddings_en": [...],
      "tags": ["man", "story", "night"]
   }

The data we currently have about the song consists of the following fields:

- **Title:** Name of the song
- **Genre:** a single-worded string containing a music style from a list of 6 
  genres
- **Artist:** Name of the artist
- **Year:** The year in which the song was written
- **Views:** Number of times the song has been listened to
- **Lyrics:** A string field containing the lyrics with each line separated by 
  a new line delimiter
- **Language:** The language of the lyrics in ISO-369. We are only storing 
  songs in English and Spanish.
- **Duration:** Duration of the song in seconds
- **Lyrics embedding vector:** language-specific embeddings vector
- **Tags:** A list of tags associated with the lyrics

The benefit of using the document data model is that it allows you to store all
the related information of a song in a single document for easy and fast 
retrieval.

Building the Solution
---------------------

In the `GitHub repository
<https://github.com/dsdlt/mongodb-scalable-document-embeddings>`__ you will
find detailed instructions on how to build the solution to update your 
embeddings asynchronously and at scale, leveraging MongoDB Atlas.

.. procedure::
   :style: normal

   .. step:: Create a MongoDB cluster

      The first step is to create a MongoDB cluster. If you don't have an 
      Atlas account, create one following the steps in this link: https://www.mongodb.com/docs/guides/atlas/account/.

      We will create a cluster in Atlas using AWS as our cloud provider and
      us-east-1 as our region. Additionally, create an Atlas Stream Processing
      Instance (SPI) following the instructions in the documentation:
      https://www.mongodb.com/docs/atlas/atlas-sp/manage-processing-instance/.
      
   .. step:: Create a Kafka cluster in Confluent

      To create a Kafka cluster in Confluent Cloud follow the instructions in 
      their documentation: https://docs.confluent.io/cloud/current/clusters/create-cluster.html#create-ak-clusters.

      Once you have created the cluster, go to cluster settings and copy the
      bootstrap URL.

      .. figure:: /includes/images/industry-solutions/createkafkacluster1.png
         :figwidth: 750px
         :alt: Kafka cluster settings

         Figure 2. Kafka cluster settings
      
      Then, create an API key to connect to your cluster.

      .. figure:: /includes/images/industry-solutions/createkafkacluster2.png
         :figwidth: 750px
         :alt: API key settings

         Figure 3. API key settings

      The next step is to configure the topics for use in this solution:
      SpanishInputTopic, EnglishInputTopic, and OutputTopic.
      
      .. figure:: /includes/images/industry-solutions/createkafkacluster3.png
         :figwidth: 1200px
         :alt: Topic settings

         Figure 4. Topic settings

   .. step:: Configure the Stream Processing connection registry

      To configure a new connection, click the configure button in the Stream
      Processing Instance, then click Connection Registry and add a new 
      connection.

      You will use this to connect the Atlas Stream Processing Instance with 
      the Kafka Cluster.

      Once you have created your Kafka cluster, Confluent will provide you with
      the bootstrap server URL, username, and password for the Connection
      Registry.
      
      .. figure:: /includes/images/industry-solutions/configurespconnection1.png
         :figwidth: 1200px
         :alt: Stream Processing connection registry settings

         Figure 5. Stream Processing connection registry settings

      Next, create a connection from the Atlas Stream Processing Instance to
      the MongoDB Atlas cluster.
      
      .. figure:: /includes/images/industry-solutions/configurespconnection2.png
         :figwidth: 1200px
         :alt: Stream Processing to Atlas settings

         Figure 6. Stream Processing to Atlas settings

   .. step:: Connect to the Stream Processing instance

      To configure the pipelines and connections in the Stream Processing 
      Instance, you can connect to the cluster using the Mongo Shell (mongosh).

      When clicking on the Connect button in the Stream Processing Instance, 
      the Atlas UI provides instructions on connecting to the instance.

      .. figure:: /includes/images/industry-solutions/connectstreamprocessing1.png
         :figwidth: 1200px
         :alt: Connect to Stream Processing

         Figure 7. Connect to Stream Processing

   .. step:: Configuring Atlas Stream Processing

      You can follow the steps to configure Atlas Stream Processing in the
      README file in the GitHub repo. There you will learn how to create the
      pipelines to subscribe to changes in MongoDB, emit to each
      language-specific topic, and merge the events containing the processed
      data with the embeddings received from the Kafka cluster into MongoDB 
      using a MongoDB aggregation stage.

   .. step:: Create the Atlas Vector Search indexes

      Next, you will create language-specific vector indexes in Atlas Search.

      Visit the `Atlas Vector Search Quick Start guide <https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/vector-search-quick-start/?tck=ai_as_web>`__ 
      and start building smarter searches.

      The definition for the Atlas Vector Search Index for Spanish is as 
      follows:

      .. code-block:: javascript
         :copyable: true

         {
            "fields": [
               {
                  "type": "vector",
                  "path": "lyrics_embeddings_es",
                  "numDimensions": 768,
                  "similarity": "cosine"
               }
            ]
         }

      The definition for the Atlas Vector Search Index for English is as
      follows:
      
      .. code-block:: javascript
         :copyable: true

         {
            "fields": [
               {
                  "type": "vector",
                  "path": "lyrics_embeddings_en",
                  "numDimensions": 384,
                  "similarity": "cosine"
               }
            ]
         }

   .. step:: Run the metadata service

      The metadata service is a Python script that will subscribe to the input
      topics, create the tags and embeddings for the corresponding language
      according to the information received in the event, and write the event 
      to the output topic.

   .. step:: Run a semantic search

      We created a script in Python to help you interactively run semantic
      queries. You can find the script in the repository under the client 
      folder.

Key Learnings
-------------

- **Maintain embedding relevancy:** Regularly update data embeddings to ensure
  your semantic searches remain accurate, especially if your documents change 
  frequently.
- **Optimize language-model pairing:** To maximize semantic search accuracy,
  ensure your large language model (LLM) closely aligns with the language of
  your data to significantly enhance the relevance and precision of your search results.
- **Embrace flexible embeddings:** MongoDB's flexible data model eliminates the
  need for rigid schema definitions. This flexibility allows you to store
  embeddings directly alongside your data, regardless of their length or the 
  model used to generate them.
- **Choose the right similarity function:** The effectiveness of your semantic
  searches depends on the chosen similarity function. Tailor your selection to 
  your specific use case.
- **Asynchronous embedding generation:** Generating embeddings can be
  computationally expensive. Consider running this task asynchronously to avoid
  impacting your application's performance. Leverage the cloud's elasticity by
  horizontally scaling the functions responsible for embedding generation to 
  handle bursts in workload.

Technologies and Products Used
------------------------------

MongoDB Developer Data Platform
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- `Atlas Database <http://mongodb.com/atlas>`__
- `Atlas Vector Search <https://www.mongodb.com/products/platform/atlas-vector-search>`__
- `Atlas Stream Processing <https://www.mongodb.com/products/platform/atlas-stream-processing>`__

Partner Technologies
~~~~~~~~~~~~~~~~~~~~

- Confluent Cloud
- AWS EC2

Author
------

David Sanchez, MongoDB
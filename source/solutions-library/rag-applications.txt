.. _arch-center-is-rag-applications:

===============================================
Building Continuously Updating RAG Applications
===============================================

.. facet::
   :name: genre
   :values: tutorial

.. meta:: 
   :keywords: RAG, Atlas
   :description: Use native stream processing and vector search in MongoDB Atlas to continuously update, store, and search embeddings through a unified interface.

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Use MongoDB Atlas native stream processing and vector search to continuously
update, store, and search embeddings through a unified interface.

**Use cases:** `Gen AI
<https://www.mongodb.com/use-cases/artificial-intelligence>`__

**Industries:** `Finance
<https://www.mongodb.com/industries/financial-services>`__,
`Healthcare <https://www.mongodb.com/industries/healthcare>`__, `Retail
<https://www.mongodb.com/industries/retail>`__

**Products:** `Atlas <http://mongodb.com/atlas>`__, `Atlas Vector Search
<https://www.mongodb.com/products/platform/atlas-vector-search>`__, `Atlas
Stream Processing
<https://www.mongodb.com/products/platform/atlas-stream-processing>`__

**Partners:** `Confluent <http://confluent.io/>`__, `AWS <https://aws.amazon.com/>`__

Solution Overview
-----------------

Providing AI models with up-to-date data is essential to delivering a
differentiated experience. Retrieval-augmented generation (`RAG
<https://www.mongodb.com/basics/retrieval-augmented-generation>`__) systems
enable organizations to ground large language models (`LLMs
<https://www.mongodb.com/basics/large-language-models>`__) and other
foundational models in the truth of their proprietary data. However, maintaining
the freshness of the underlying data introduces a layer of complexity. To ensure
models provide accurate answers, it is essential to continuously update the
vector embeddings that form the core of RAG systems to represent the latest
information available. 

Furthermore, the choice of embedding model impacts the quality of AI outputs due
to how different models are optimized for varying purposes and data types. For
example, an embedding model trained on a particular language will create more
contextually appropriate embeddings for that language than a general-purpose
model trained across many languages.

By leveraging MongoDB Atlas' native `Stream Processing
<https://www.mongodb.com/products/platform/atlas-stream-processing>`__ and
`Vector Search
<https://www.mongodb.com/products/platform/atlas-vector-search>`__ capabilities,
this solution addresses this issue of continuously updating and routing vector
embeddings in a RAG system. With this solution, developers can continuously
update, store, and search embeddings within a single interface.

This solution is relevant to many industries and use cases, including:

- **Financial services:** Financial documents, legal policies, and contracts
  often use multiple languages and differ based on country regulations.
  Empowering loan officers with an AI-powered interface using relevant and fresh
  data for expediting loan creation can optimize banking workflows.

- **Healthcare and Insurance:** From constantly updating patient records to 
  AI-powered underwriting of insurance policies, itâ€™s important that any RAG 
  system that optimizes these processes has access to the latest information.

- **Retail:** Personalizing retail experiences for customers is critical.
  However, consider the many languages that shoppers might use and product
  descriptions that have to match. Routing up-to-date, contextual data to the
  most accurate embedding model can improve these experiences.

Reference Architectures
-----------------------

- **MongoDB Atlas Cluster:** Enables the flexible storage of various data types
  including text, associated metadata, and corresponding vector embeddings in
  documents. Atlas's vector index capability directly supports efficient
  semantic search queries within the database, which can be leveraged through
  the `MongoDB Aggregation Framework
  <https://www.mongodb.com/basics/aggregation>`__.

- **Atlas Stream Processing:** Subscribes to the event streams generated by
  MongoDB, filters relevant information, transforms events, and emits them to
  the corresponding Kafka topic. It also subscribes to the Kafka cluster to
  process updates and propagate changes back to the database.

- **Confluent Kafka Cluster:** Receives document updates and new documents from
  producers and makes them available for further processing by Atlas Stream
  Processing.

- **Metadata Service:**

  - **Embedding Generator:** Python script that subscribes to the Kafka input
    topics. For each message received, it generates an embedding using a
    specialized machine learning model.

  - **Tags Extractor:** Python script that analyzes incoming data to identify
    relevant structured metadata to enrich the document for indexing, search, or
    analysis.

.. figure:: /includes/images/industry-solutions/RefArchitecture_StreamProcessing_WithMongoDB.svg
   :figwidth: 1200px
   :alt: Scalable vector updates reference architecture with MongoDB

   Figure 1. Scalable vector updates reference architecture with MongoDB

Data Model Approach
-------------------

In the demo solution, the data model is a collection of documents that
encapsulate all relevant information about a song. This approach leverages the
flexibility of the document data model to store diverse data types alongside
their embeddings, allowing for easy and fast retrieval. 

The `sample data
<https://github.com/dsdlt/mongodb-scalable-document-embeddings/tree/main/dataset>`__
has two datasets available for import: ``archive_lyrics_small1`` and
``archive_lyrics_small2``. The documents in these datasets have the following
structure:

.. code-block:: javascript
   :copyable: true
   :emphasize-lines: 9-10

   {
      "title": "Hurricane",
      "artist": "Bob Dylan",
      "year": 1976,
      "lyrics": "...",
      "language": "en",
      "genre": "rock",
      "duration": 61,
      "lyrics_embeddings_en": [...],
      "tags": ["man", "story", "night"]   // only in archive_lyrics_small1
   }

The relevant data fields are:

- ``lyrics_embeddings_en``/``lyrics_embeddings_es``: Language-specific lyrics
  embedding vector

- ``tags``: Only in the ``archive_lyrics_small1`` dataset, lists frequently
  occurring words in the lyrics

Building the Solution
---------------------

The `GitHub repository
<https://github.com/dsdlt/mongodb-scalable-document-embeddings>`__ contains
detailed instructions on how to build the solution to update your embeddings
asynchronously and at scale, leveraging MongoDB Atlas. 

The ``README`` guides you through the following steps:

.. procedure::
   :style: normal

   .. step:: Set up the Environment

      Clone the repository, set up a virtual environment, and install necessary dependencies.

   .. step:: Load the Dataset
      
      .. important:: 

         If you don't already have an Atlas account, :ref:`join now
         <guides-create-atlas-account>` and :ref:`create a cluster
         <guides-create-a-cluster>`.

      Use the `provided script
      <https://github.com/dsdlt/mongodb-scalable-document-embeddings/blob/main/dataset/data_load.sh>`__
      to load the data with :ref:`<mongoimport>`.

   .. step:: Configure a Kafka Cluster in Confluent

      Follow the instructions in the `Confluent documentation
      <https://docs.confluent.io/cloud/current/clusters/create-cluster.html#create-ak-clusters>`__
      to create a Kafka Cluster.

      .. _copy-bootstrap-URL:
      
      Copy your bootstrap URL from the ``Cluster Settings`` tab on Confluent.
      
      Use the Kafka REST API and create an API key to connect to your cluster.

      Configure the topics ``SpanishInputTopic``, ``EnglishInputTopic``, and
      ``OutputTopic`` in the ``Topics`` tab on Confluent.

   .. step:: Configure the Stream Processing Connection Registry

      Use the :ref:`Confluent bootstrap URL <copy-bootstrap-URL>` in the
      connection registry to configure a new connection in :ref:`Atlas Stream Processing
      <atlas-sp-tutorial>` that connects the instance with the Kafka Cluster.

      Connect the Atlas Stream Processing Instance to the Atlas cluster.
      
      .. figure:: /includes/images/industry-solutions/configurespconnection2.png
         :figwidth: 500px
         :alt: Stream Processing to Atlas settings

         Figure 6. Stream Processing to Atlas settings

   .. step:: Configure Atlas Stream Processing

      Copy your `connection string
      <https://www.mongodb.com/docs/atlas/atlas-stream-processing/tutorial/#get-the-stream-processing-instance-connection-string.>`__
      for connecting to the Stream Processing Instance.

      Use the :ref:`MongoDB Shell (mongosh) <mdb-shell-overview>` to configure
      the pipelines and connections in the Stream Processing Instance.

   .. step:: Launch the Processor Scripts

      Execute the metadata service to subscribe to the input topics, create the
      tags and embeddings for the corresponding language according to the
      information received in the event, and write the event to the output
      topic.

   .. step:: Create an Atlas Vector Search Index

      Next, you will create language-specific vector indexes in Atlas Search.

      Visit the `Atlas Vector Search Quick Start guide <https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/vector-search-quick-start/?tck=ai_as_web>`__ 
      and start building smarter searches.

      The definition for the Atlas Vector Search Index for Spanish is as 
      follows:

      .. code-block:: javascript
         :copyable: true

         {
            "fields": [
               {
                  "type": "vector",
                  "path": "lyrics_embeddings_es",
                  "numDimensions": 768,
                  "similarity": "cosine"
               }
            ]
         }

      The definition for the Atlas Vector Search Index for English is as
      follows:
      
      .. code-block:: javascript
         :copyable: true

         {
            "fields": [
               {
                  "type": "vector",
                  "path": "lyrics_embeddings_en",
                  "numDimensions": 384,
                  "similarity": "cosine"
               }
            ]
         }

   .. step:: Run a semantic search

      We created a script in Python to help you interactively run semantic
      queries. You can find the script in the repository under the client 
      folder.

Key Learnings
-------------

- **Maintain embedding relevancy:** Regularly update data embeddings to ensure
  your semantic searches remain accurate, especially if your documents change 
  frequently.
  
- **Optimize language-model pairing:** To maximize semantic search accuracy,
  ensure your large language model (LLM) closely aligns with the language of
  your data to significantly enhance the relevance and precision of your search results.

- **Embrace flexible embeddings:** MongoDB's flexible data model eliminates the
  need for rigid schema definitions. This flexibility allows you to store
  embeddings directly alongside your data, regardless of their length or the 
  model used to generate them.

- **Choose the right similarity function:** The effectiveness of your semantic
  searches depends on the chosen similarity function. Tailor your selection to 
  your specific use case.

- **Asynchronous embedding generation:** Generating embeddings can be
  computationally expensive. Consider running this task asynchronously to avoid
  impacting your application's performance. Leverage the cloud's elasticity by
  horizontally scaling the functions responsible for embedding generation to 
  handle bursts in workload.

Learn More
----------

To learn more about the products and technologies in this solution, see the
associated links below.

MongoDB Developer Data Platform
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- `Atlas Database <http://mongodb.com/atlas>`__
- `Atlas Vector Search <https://www.mongodb.com/products/platform/atlas-vector-search>`__
- `Atlas Stream Processing <https://www.mongodb.com/products/platform/atlas-stream-processing>`__

Partner Technologies
~~~~~~~~~~~~~~~~~~~~

- `Confluent Cloud <https://www.confluent.io/confluent-cloud/>`__
- `Amazon EC2 <https://aws.amazon.com/pm/ec2/>`__

Author
------

David Sanchez, MongoDB